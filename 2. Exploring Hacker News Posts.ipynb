{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "In this project, we'll work with a data set of submissions to popular technology site Hacker News.\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "You can find the data set on https://www.kaggle.com/hacker-news/hacker-news-posts, but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions.\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either Ask HN or Show HN. Users submit Ask HN posts to ask the Hacker News community a specific question. Below are a couple examples:\n",
    "\n",
    "- *Ask HN: How to improve my personal website?*\n",
    "- *Ask HN: Am I the only one outraged by Twitter shutting down share counts?*\n",
    "- *Ask HN: Aby recent changes to CSS that broke mobile?*\n",
    "\n",
    "Likewise, users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting. Below are a couple of examples:\n",
    "\n",
    "- *Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform'*\n",
    "- *Show HN: Something pointless I made*\n",
    "- *Show HN: Shanhu.io, a programming playground powered by e8vm*\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    "- Do Ask HN or Show HN receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "Let's start by importing the libraries we need and reading the data set into a list of lists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12'], ['10482257', 'Title II kills investment? Comcast and other ISPs are now spending more', 'http://arstechnica.com/business/2015/10/comcast-and-other-isps-boost-network-investment-despite-net-neutrality/', '53', '22', 'Deinos', '10/31/2015 9:48']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "open_file = open(\"data/hacker_news.csv\")\n",
    "read_file = reader(open_file)\n",
    "dataset = list(read_file)\n",
    "headers = dataset[0]\n",
    "dataset = dataset[1:]\n",
    "print(headers)\n",
    "print(dataset[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's seperate ask post and show posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ASK HN ***\n",
      "[['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14'], ['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20']]\n",
      "\n",
      "*** SHOW HN ***\n",
      "[['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46'], ['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05'], ['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11']]\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in dataset:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(\"*** ASK HN ***\")\n",
    "print(ask_posts[1:4])\n",
    "print(\"\\n*** SHOW HN ***\")\n",
    "print(show_posts[1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since now we can start working on the first question: what posts receive more comments on average.\n",
    "\n",
    "To answer the question, we will build the function that takes the list of posts and index of comments as the input and outputs average number of comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_comments(posts, index):\n",
    "    total = 0\n",
    "    for row in posts:\n",
    "        comments = int(row[index]) #4\n",
    "        total += comments\n",
    "    avg_comments = total/len(posts)\n",
    "    return avg_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print average numbers of comments of each type and compare those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASK HN average number of comments: 14.038417431192661\n",
      "SHOW HN average number of comments: 10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "ask_avg_comments = avg_comments(ask_posts, 4)\n",
    "print(\"ASK HN average number of comments:\", ask_avg_comments)\n",
    "show_avg_comments = avg_comments(show_posts, 4)\n",
    "print(\"SHOW HN average number of comments:\", show_avg_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the number of comments of ASK HN type is higher than SHOW HN\n",
    "\n",
    "Let's answer now the second question - Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "To do that we will need to import another library - datetime and create two dictionaries of comments by hour and count of posts by hour where we will store hours as keys and number of comments/posts as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    comments = row[4]\n",
    "    result_list.append([created_at, comments])\n",
    "    \n",
    "count_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    create_date = dt.datetime.strptime(row[0], \"%m/%d/%Y %H:%M\")\n",
    "    create_date = create_date + dt.timedelta(hours = 5) # EST time +5 hours = BST time\n",
    "    comments = int(row[1])\n",
    "    create_hour = create_date.strftime(\"%H\")\n",
    "    \n",
    "    if create_hour in count_by_hour:\n",
    "        count_by_hour[create_hour] += 1\n",
    "        comments_by_hour[create_hour] += comments\n",
    "    else:\n",
    "        count_by_hour[create_hour] = 1\n",
    "        comments_by_hour[create_hour] = comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two dictionaries - count_by_hour and comments_by_our. Next, we can iterate over one of the dictionaries and get the average number of comment per hour by dividing number of comments per hour by number of posts per hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['14', 5.5777777777777775], ['18', 14.741176470588234], ['15', 13.440677966101696], ['19', 13.233644859813085], ['21', 16.796296296296298], ['04', 7.985294117647059], ['17', 9.41095890410959], ['22', 11.46], ['20', 38.5948275862069], ['02', 16.009174311926607], ['01', 21.525], ['07', 23.810344827586206], ['23', 13.20183486238532], ['08', 7.796296296296297], ['10', 10.08695652173913], ['00', 10.8], ['06', 11.383333333333333], ['03', 6.746478873239437], ['13', 10.25], ['09', 7.170212765957447], ['05', 8.127272727272727], ['11', 9.022727272727273], ['12', 7.852941176470588], ['16', 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour_list = []\n",
    "for item in count_by_hour:\n",
    "    avg_by_hour = int(comments_by_hour[item])/int(count_by_hour[item])\n",
    "    avg_by_hour_list.append([item, avg_by_hour])\n",
    "print(avg_by_hour_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our final output - the list of lists of average comments by hour. It seems to be difficult to analyze data in ths format. \n",
    "\n",
    "Let's print top 5 hours by average comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TOP 5 Hours for Ask Posts Comments\n",
      "20:00: 38.59 average comments per post\n",
      "07:00: 23.81 average comments per post\n",
      "01:00: 21.52 average comments per post\n",
      "21:00: 16.80 average comments per post\n",
      "02:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour_list = []\n",
    "for row in avg_by_hour_list:\n",
    "    swap_avg_by_hour_list.append([row[1], row[0]])\n",
    "    \n",
    "sorted_swap_list = sorted(swap_avg_by_hour_list, reverse = True)\n",
    "\n",
    "print(\"*** TOP 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for row in sorted_swap_list[0:5]:\n",
    "    print(\"{}:00: {:.2f} average comments per post\".format(row[1], row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "During this project we have answered two questions - what type of posts have more comments on average and what are top 5 hours for ask posts comments. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
